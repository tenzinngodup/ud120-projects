{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================================\n",
      "Faces recognition example using eigenfaces and SVMs\n",
      "===================================================\n",
      "\n",
      "The dataset used in this example is a preprocessed excerpt of the\n",
      "\"Labeled Faces in the Wild\", aka LFW_:\n",
      "\n",
      "  http://vis-www.cs.umass.edu/lfw/lfw-funneled.tgz (233MB)\n",
      "\n",
      "  .. _LFW: http://vis-www.cs.umass.edu/lfw/\n",
      "\n",
      "  original source: http://scikit-learn.org/stable/auto_examples/applications/face_recognition.html\n",
      "\n",
      "\n",
      "Total dataset size:\n",
      "n_samples: 1288\n",
      "n_features: 1850\n",
      "n_classes: 7\n",
      "Extracting the top 150 eigenfaces from 966 faces\n",
      "done in 0.475s\n",
      "Projecting the input data on the eigenfaces orthonormal basis\n",
      "done in 0.096s\n",
      "Fitting the classifier to the training set\n",
      "done in 15.940s\n",
      "Best estimator found by grid search:\n",
      "SVC(C=1000.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=0.001, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Predicting the people names on the testing set\n",
      "done in 0.050s\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "     Ariel Sharon       0.50      0.62      0.55        13\n",
      "     Colin Powell       0.76      0.88      0.82        60\n",
      "  Donald Rumsfeld       0.73      0.70      0.72        27\n",
      "    George W Bush       0.92      0.87      0.89       146\n",
      "Gerhard Schroeder       0.77      0.80      0.78        25\n",
      "      Hugo Chavez       0.75      0.60      0.67        15\n",
      "       Tony Blair       0.88      0.83      0.86        36\n",
      "\n",
      "      avg / total       0.83      0.83      0.83       322\n",
      "\n",
      "[[  8   0   3   2   0   0   0]\n",
      " [  2  53   1   3   0   1   0]\n",
      " [  4   1  19   2   0   0   1]\n",
      " [  1  11   2 127   3   1   1]\n",
      " [  0   2   0   1  20   1   1]\n",
      " [  0   2   0   1   2   9   1]\n",
      " [  1   1   1   2   1   0  30]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "===================================================\n",
    "Faces recognition example using eigenfaces and SVMs\n",
    "===================================================\n",
    "\n",
    "The dataset used in this example is a preprocessed excerpt of the\n",
    "\"Labeled Faces in the Wild\", aka LFW_:\n",
    "\n",
    "  http://vis-www.cs.umass.edu/lfw/lfw-funneled.tgz (233MB)\n",
    "\n",
    "  .. _LFW: http://vis-www.cs.umass.edu/lfw/\n",
    "\n",
    "  original source: http://scikit-learn.org/stable/auto_examples/applications/face_recognition.html\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "print __doc__\n",
    "\n",
    "from time import time\n",
    "import logging\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import RandomizedPCA\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Display progress logs on stdout\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(message)s')\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# Download the data, if not already on disk and load it as numpy arrays\n",
    "lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\n",
    "\n",
    "# introspect the images arrays to find the shapes (for plotting)\n",
    "n_samples, h, w = lfw_people.images.shape\n",
    "np.random.seed(42)\n",
    "\n",
    "# for machine learning we use the data directly (as relative pixel\n",
    "# position info is ignored by this model)\n",
    "X = lfw_people.data\n",
    "n_features = X.shape[1]\n",
    "\n",
    "# the label to predict is the id of the person\n",
    "y = lfw_people.target\n",
    "target_names = lfw_people.target_names\n",
    "n_classes = target_names.shape[0]\n",
    "\n",
    "print \"Total dataset size:\"\n",
    "print \"n_samples: %d\" % n_samples\n",
    "print \"n_features: %d\" % n_features\n",
    "print \"n_classes: %d\" % n_classes\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# Split into a training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "###############################################################################\n",
    "# Compute a PCA (eigenfaces) on the face dataset (treated as unlabeled\n",
    "# dataset): unsupervised feature extraction / dimensionality reduction\n",
    "n_components = 100\n",
    "\n",
    "print \"Extracting the top %d eigenfaces from %d faces\" % (n_components, X_train.shape[0])\n",
    "t0 = time()\n",
    "pca = RandomizedPCA(n_components=n_components, whiten=True).fit(X_train)\n",
    "print \"done in %0.3fs\" % (time() - t0)\n",
    "\n",
    "eigenfaces = pca.components_.reshape((n_components, h, w))\n",
    "\n",
    "print \"Projecting the input data on the eigenfaces orthonormal basis\"\n",
    "t0 = time()\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "print \"done in %0.3fs\" % (time() - t0)\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# Train a SVM classification model\n",
    "\n",
    "print \"Fitting the classifier to the training set\"\n",
    "t0 = time()\n",
    "param_grid = {\n",
    "         'C': [1e3, 5e3, 1e4, 5e4, 1e5],\n",
    "          'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1],\n",
    "          }\n",
    "# for sklearn version 0.16 or prior, the class_weight parameter value is 'auto'\n",
    "clf = GridSearchCV(SVC(kernel='rbf', class_weight='balanced'), param_grid)\n",
    "clf = clf.fit(X_train_pca, y_train)\n",
    "print \"done in %0.3fs\" % (time() - t0)\n",
    "print \"Best estimator found by grid search:\"\n",
    "print clf.best_estimator_\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# Quantitative evaluation of the model quality on the test set\n",
    "\n",
    "print \"Predicting the people names on the testing set\"\n",
    "t0 = time()\n",
    "y_pred = clf.predict(X_test_pca)\n",
    "print \"done in %0.3fs\" % (time() - t0)\n",
    "\n",
    "print classification_report(y_test, y_pred, target_names=target_names)\n",
    "print confusion_matrix(y_test, y_pred, labels=range(n_classes))\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# Qualitative evaluation of the predictions using matplotlib\n",
    "\n",
    "def plot_gallery(images, titles, h, w, n_row=3, n_col=4):\n",
    "    \"\"\"Helper function to plot a gallery of portraits\"\"\"\n",
    "    pl.figure(figsize=(1.8 * n_col, 2.4 * n_row))\n",
    "    pl.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n",
    "    for i in range(n_row * n_col):\n",
    "        pl.subplot(n_row, n_col, i + 1)\n",
    "        pl.imshow(images[i].reshape((h, w)), cmap=pl.cm.gray)\n",
    "        pl.title(titles[i], size=12)\n",
    "        pl.xticks(())\n",
    "        pl.yticks(())\n",
    "\n",
    "\n",
    "# plot the result of the prediction on a portion of the test set\n",
    "\n",
    "def title(y_pred, y_test, target_names, i):\n",
    "    pred_name = target_names[y_pred[i]].rsplit(' ', 1)[-1]\n",
    "    true_name = target_names[y_test[i]].rsplit(' ', 1)[-1]\n",
    "    return 'predicted: %s\\ntrue:      %s' % (pred_name, true_name)\n",
    "\n",
    "prediction_titles = [title(y_pred, y_test, target_names, i)\n",
    "                         for i in range(y_pred.shape[0])]\n",
    "\n",
    "plot_gallery(X_test, prediction_titles, h, w)\n",
    "\n",
    "# plot the gallery of the most significative eigenfaces\n",
    "\n",
    "eigenface_titles = [\"eigenface %d\" % i for i in range(eigenfaces.shape[0])]\n",
    "plot_gallery(eigenfaces, eigenface_titles, h, w)\n",
    "\n",
    "pl.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================================\n",
      "Faces recognition example using eigenfaces and SVMs\n",
      "===================================================\n",
      "\n",
      "The dataset used in this example is a preprocessed excerpt of the\n",
      "\"Labeled Faces in the Wild\", aka LFW_:\n",
      "\n",
      "  http://vis-www.cs.umass.edu/lfw/lfw-funneled.tgz (233MB)\n",
      "\n",
      "  .. _LFW: http://vis-www.cs.umass.edu/lfw/\n",
      "\n",
      "  original source: http://scikit-learn.org/stable/auto_examples/applications/face_recognition.html\n",
      "\n",
      "\n",
      "Total dataset size:\n",
      "n_samples: 1288\n",
      "n_features: 1850\n",
      "n_classes: 7\n",
      "Extracting the top 10 eigenfaces from 966 faces\n",
      "done in 0.107s\n",
      "Projecting the input data on the eigenfaces orthonormal basis\n",
      "done in 0.020s\n",
      "Fitting the classifier to the training set\n",
      "done in 47.922s\n",
      "Best estimator found by grid search:\n",
      "SVC(C=1000.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=0.1, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Predicting the people names on the testing set\n",
      "done in 0.008s\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "     Ariel Sharon       0.10      0.15      0.12        13\n",
      "     Colin Powell       0.45      0.55      0.49        60\n",
      "  Donald Rumsfeld       0.29      0.37      0.33        27\n",
      "    George W Bush       0.67      0.60      0.63       146\n",
      "Gerhard Schroeder       0.19      0.20      0.20        25\n",
      "      Hugo Chavez       0.25      0.13      0.17        15\n",
      "       Tony Blair       0.48      0.39      0.43        36\n",
      "\n",
      "      avg / total       0.50      0.48      0.48       322\n",
      "\n",
      "[[ 2  5  2  3  1  0  0]\n",
      " [ 8 33  2 10  3  1  3]\n",
      " [ 2  9 10  5  0  0  1]\n",
      " [ 7 20  8 87 12  4  8]\n",
      " [ 0  2  4 10  5  1  3]\n",
      " [ 1  2  2  8  0  2  0]\n",
      " [ 1  3  6  7  5  0 14]]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 10 is out of bounds for axis 0 with size 10",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-dae818994369>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0meigenface_titles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"eigenface %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meigenfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m \u001b[0mplot_gallery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meigenfaces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meigenface_titles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-dae818994369>\u001b[0m in \u001b[0;36mplot_gallery\u001b[0;34m(images, titles, h, w, n_row, n_col)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_row\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_row\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 10 is out of bounds for axis 0 with size 10"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "===================================================\n",
    "Faces recognition example using eigenfaces and SVMs\n",
    "===================================================\n",
    "\n",
    "The dataset used in this example is a preprocessed excerpt of the\n",
    "\"Labeled Faces in the Wild\", aka LFW_:\n",
    "\n",
    "  http://vis-www.cs.umass.edu/lfw/lfw-funneled.tgz (233MB)\n",
    "\n",
    "  .. _LFW: http://vis-www.cs.umass.edu/lfw/\n",
    "\n",
    "  original source: http://scikit-learn.org/stable/auto_examples/applications/face_recognition.html\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "print __doc__\n",
    "\n",
    "from time import time\n",
    "import logging\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import RandomizedPCA\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Display progress logs on stdout\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(message)s')\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# Download the data, if not already on disk and load it as numpy arrays\n",
    "lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\n",
    "\n",
    "# introspect the images arrays to find the shapes (for plotting)\n",
    "n_samples, h, w = lfw_people.images.shape\n",
    "np.random.seed(42)\n",
    "\n",
    "# for machine learning we use the data directly (as relative pixel\n",
    "# position info is ignored by this model)\n",
    "X = lfw_people.data\n",
    "n_features = X.shape[1]\n",
    "\n",
    "# the label to predict is the id of the person\n",
    "y = lfw_people.target\n",
    "target_names = lfw_people.target_names\n",
    "n_classes = target_names.shape[0]\n",
    "\n",
    "print \"Total dataset size:\"\n",
    "print \"n_samples: %d\" % n_samples\n",
    "print \"n_features: %d\" % n_features\n",
    "print \"n_classes: %d\" % n_classes\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# Split into a training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "###############################################################################\n",
    "# Compute a PCA (eigenfaces) on the face dataset (treated as unlabeled\n",
    "# dataset): unsupervised feature extraction / dimensionality reduction\n",
    "n_components = 10\n",
    "\n",
    "print \"Extracting the top %d eigenfaces from %d faces\" % (n_components, X_train.shape[0])\n",
    "t0 = time()\n",
    "pca = RandomizedPCA(n_components=n_components, whiten=True).fit(X_train)\n",
    "print \"done in %0.3fs\" % (time() - t0)\n",
    "\n",
    "eigenfaces = pca.components_.reshape((n_components, h, w))\n",
    "\n",
    "print \"Projecting the input data on the eigenfaces orthonormal basis\"\n",
    "t0 = time()\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "print \"done in %0.3fs\" % (time() - t0)\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# Train a SVM classification model\n",
    "\n",
    "print \"Fitting the classifier to the training set\"\n",
    "t0 = time()\n",
    "param_grid = {\n",
    "         'C': [1e3, 5e3, 1e4, 5e4, 1e5],\n",
    "          'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1],\n",
    "          }\n",
    "# for sklearn version 0.16 or prior, the class_weight parameter value is 'auto'\n",
    "clf = GridSearchCV(SVC(kernel='rbf', class_weight='balanced'), param_grid)\n",
    "clf = clf.fit(X_train_pca, y_train)\n",
    "print \"done in %0.3fs\" % (time() - t0)\n",
    "print \"Best estimator found by grid search:\"\n",
    "print clf.best_estimator_\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# Quantitative evaluation of the model quality on the test set\n",
    "\n",
    "print \"Predicting the people names on the testing set\"\n",
    "t0 = time()\n",
    "y_pred = clf.predict(X_test_pca)\n",
    "print \"done in %0.3fs\" % (time() - t0)\n",
    "\n",
    "print classification_report(y_test, y_pred, target_names=target_names)\n",
    "print confusion_matrix(y_test, y_pred, labels=range(n_classes))\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# Qualitative evaluation of the predictions using matplotlib\n",
    "\n",
    "def plot_gallery(images, titles, h, w, n_row=3, n_col=4):\n",
    "    \"\"\"Helper function to plot a gallery of portraits\"\"\"\n",
    "    pl.figure(figsize=(1.8 * n_col, 2.4 * n_row))\n",
    "    pl.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n",
    "    for i in range(n_row * n_col):\n",
    "        pl.subplot(n_row, n_col, i + 1)\n",
    "        pl.imshow(images[i].reshape((h, w)), cmap=pl.cm.gray)\n",
    "        pl.title(titles[i], size=12)\n",
    "        pl.xticks(())\n",
    "        pl.yticks(())\n",
    "\n",
    "\n",
    "# plot the result of the prediction on a portion of the test set\n",
    "\n",
    "def title(y_pred, y_test, target_names, i):\n",
    "    pred_name = target_names[y_pred[i]].rsplit(' ', 1)[-1]\n",
    "    true_name = target_names[y_test[i]].rsplit(' ', 1)[-1]\n",
    "    return 'predicted: %s\\ntrue:      %s' % (pred_name, true_name)\n",
    "\n",
    "prediction_titles = [title(y_pred, y_test, target_names, i)\n",
    "                         for i in range(y_pred.shape[0])]\n",
    "\n",
    "plot_gallery(X_test, prediction_titles, h, w)\n",
    "\n",
    "# plot the gallery of the most significative eigenfaces\n",
    "\n",
    "eigenface_titles = [\"eigenface %d\" % i for i in range(eigenfaces.shape[0])]\n",
    "plot_gallery(eigenfaces, eigenface_titles, h, w)\n",
    "\n",
    "pl.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1850"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "===================================================\n",
    "Faces recognition example using eigenfaces and SVMs\n",
    "===================================================\n",
    "\n",
    "The dataset used in this example is a preprocessed excerpt of the\n",
    "\"Labeled Faces in the Wild\", aka LFW_:\n",
    "\n",
    "  http://vis-www.cs.umass.edu/lfw/lfw-funneled.tgz (233MB)\n",
    "\n",
    "  .. _LFW: http://vis-www.cs.umass.edu/lfw/\n",
    "\n",
    "  original source: http://scikit-learn.org/stable/auto_examples/applications/face_recognition.html\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "print __doc__\n",
    "\n",
    "from time import time\n",
    "import logging\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import RandomizedPCA\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Display progress logs on stdout\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(message)s')\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# Download the data, if not already on disk and load it as numpy arrays\n",
    "lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\n",
    "\n",
    "# introspect the images arrays to find the shapes (for plotting)\n",
    "n_samples, h, w = lfw_people.images.shape\n",
    "np.random.seed(42)\n",
    "\n",
    "# for machine learning we use the data directly (as relative pixel\n",
    "# position info is ignored by this model)\n",
    "X = lfw_people.data\n",
    "n_features = X.shape[1]\n",
    "\n",
    "# the label to predict is the id of the person\n",
    "y = lfw_people.target\n",
    "target_names = lfw_people.target_names\n",
    "n_classes = target_names.shape[0]\n",
    "\n",
    "print \"Total dataset size:\"\n",
    "print \"n_samples: %d\" % n_samples\n",
    "print \"n_features: %d\" % n_features\n",
    "print \"n_classes: %d\" % n_classes\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# Split into a training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "###############################################################################\n",
    "# Compute a PCA (eigenfaces) on the face dataset (treated as unlabeled\n",
    "# dataset): unsupervised feature extraction / dimensionality reduction\n",
    "n_components = 15\n",
    "\n",
    "print \"Extracting the top %d eigenfaces from %d faces\" % (n_components, X_train.shape[0])\n",
    "t0 = time()\n",
    "pca = RandomizedPCA(n_components=n_components, whiten=True).fit(X_train)\n",
    "print \"done in %0.3fs\" % (time() - t0)\n",
    "\n",
    "eigenfaces = pca.components_.reshape((n_components, h, w))\n",
    "\n",
    "print \"Projecting the input data on the eigenfaces orthonormal basis\"\n",
    "t0 = time()\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "print \"done in %0.3fs\" % (time() - t0)\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# Train a SVM classification model\n",
    "\n",
    "print \"Fitting the classifier to the training set\"\n",
    "t0 = time()\n",
    "param_grid = {\n",
    "         'C': [1e3, 5e3, 1e4, 5e4, 1e5],\n",
    "          'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1],\n",
    "          }\n",
    "# for sklearn version 0.16 or prior, the class_weight parameter value is 'auto'\n",
    "clf = GridSearchCV(SVC(kernel='rbf', class_weight='balanced'), param_grid)\n",
    "clf = clf.fit(X_train_pca, y_train)\n",
    "print \"done in %0.3fs\" % (time() - t0)\n",
    "print \"Best estimator found by grid search:\"\n",
    "print clf.best_estimator_\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# Quantitative evaluation of the model quality on the test set\n",
    "\n",
    "print \"Predicting the people names on the testing set\"\n",
    "t0 = time()\n",
    "y_pred = clf.predict(X_test_pca)\n",
    "print \"done in %0.3fs\" % (time() - t0)\n",
    "\n",
    "print classification_report(y_test, y_pred, target_names=target_names)\n",
    "print confusion_matrix(y_test, y_pred, labels=range(n_classes))\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# Qualitative evaluation of the predictions using matplotlib\n",
    "\n",
    "def plot_gallery(images, titles, h, w, n_row=3, n_col=4):\n",
    "    \"\"\"Helper function to plot a gallery of portraits\"\"\"\n",
    "    pl.figure(figsize=(1.8 * n_col, 2.4 * n_row))\n",
    "    pl.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n",
    "    for i in range(n_row * n_col):\n",
    "        pl.subplot(n_row, n_col, i + 1)\n",
    "        pl.imshow(images[i].reshape((h, w)), cmap=pl.cm.gray)\n",
    "        pl.title(titles[i], size=12)\n",
    "        pl.xticks(())\n",
    "        pl.yticks(())\n",
    "\n",
    "\n",
    "# plot the result of the prediction on a portion of the test set\n",
    "\n",
    "def title(y_pred, y_test, target_names, i):\n",
    "    pred_name = target_names[y_pred[i]].rsplit(' ', 1)[-1]\n",
    "    true_name = target_names[y_test[i]].rsplit(' ', 1)[-1]\n",
    "    return 'predicted: %s\\ntrue:      %s' % (pred_name, true_name)\n",
    "\n",
    "prediction_titles = [title(y_pred, y_test, target_names, i)\n",
    "                         for i in range(y_pred.shape[0])]\n",
    "\n",
    "plot_gallery(X_test, prediction_titles, h, w)\n",
    "\n",
    "# plot the gallery of the most significative eigenfaces\n",
    "\n",
    "eigenface_titles = [\"eigenface %d\" % i for i in range(eigenfaces.shape[0])]\n",
    "plot_gallery(eigenfaces, eigenface_titles, h, w)\n",
    "\n",
    "pl.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ariel Sharon', 'Colin Powell', 'Donald Rumsfeld', 'George W Bush',\n",
       "       'Gerhard Schroeder', 'Hugo Chavez', 'Tony Blair'], \n",
       "      dtype='|S17')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lfw_people.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99244289  0.00755711]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, n_components=2, whiten=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(X)\n",
    "print(pca.explained_variance_ratio_) \n",
    "pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(966, 1850)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-27bb8d0b97c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0;36m138.66667175\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m147.33332825\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m148.66667175\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m239.33332825\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m247.66667175\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m245.66667175\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "x = pd.dataframe([[ 138.66667175,  147.33332825,  148.66667175,239.33332825,247.66667175,  245.66667175]])\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
